{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2.0教程-张量极其操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标量、向量、矩阵、张量之间的联系\n",
    "**标量（scalar）**\n",
    "一个标量表示一个单独的数，它不同于线性代数中研究的其他大部分对象（通常是多个数的数组）。我们用斜体表示标量。标量通常被赋予小写的变量名称。\n",
    "\n",
    "**向量（vector）**\n",
    "​一个向量表示一组有序排列的数。通过次序中的索引，我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称，比如xx。向量中的元素可以通过带脚标的斜体表示。向量$X$的第一个元素是$X_1$，第二个元素是$X_2$，以此类推。我们也会注明存储在向量中的元素的类型（实数、虚数等）。\n",
    "\n",
    "**矩阵（matrix）**\n",
    "​矩阵是具有相同特征和纬度的对象的集合，表现为一张二维数据表。其意义是一个对象表示为矩阵中的一行，一个特征表示为矩阵中的一列，每个特征都有数值型的取值。通常会赋予矩阵粗体的大写变量名称，比如$A$。\n",
    "\n",
    "**张量（tensor）**\n",
    "​在某些情况下，我们会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。使用 $A$ 来表示张量“A”。张量$A$中坐标为$(i,j,k)$的元素记作$A_{(i,j,k)}$。\n",
    "\n",
    "**四者之间关系**\n",
    "\n",
    "> 标量是0阶张量，向量是一阶张量。举例：\n",
    "> ​标量就是知道棍子的长度，但是你不会知道棍子指向哪儿。\n",
    "> ​向量就是不但知道棍子的长度，还知道棍子指向前面还是后面。\n",
    "> ​张量就是不但知道棍子的长度，也知道棍子指向前面还是后面，还能知道这棍子又向上/下和左/右偏转了多少。\n",
    "\n",
    "### 张量与矩阵的区别\n",
    "\n",
    "- 从代数角度讲， 矩阵它是向量的推广。向量可以看成一维的“表格”（即分量按照顺序排成一排）， 矩阵是二维的“表格”（分量按照纵横位置排列）， 那么$n$阶张量就是所谓的$n$维的“表格”。 张量的严格定义是利用线性映射来描述。\n",
    "- 从几何角度讲， 矩阵是一个真正的几何量，也就是说，它是一个不随参照系的坐标变换而变化的东西。向量也具有这种特性。\n",
    "- 张量可以用3×3矩阵形式来表达。\n",
    "- 表示标量的数和表示向量的三维数组也可分别看作1×1，1×3的矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入TensorFlow\n",
    "运行tensorflow程序，需要导入tensorflow模块。\n",
    "从TensorFlow 2.0开始，默认情况下会启用急切执行。 这为TensorFlow提供了一个更加互动的前端节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Hello TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1, shape=(), dtype=string, numpy=b'Hello TesorFlow'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant('Hello TesorFlow')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello TesorFlow'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Tensor to Numpy.\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Tensors\n",
    "张量是一个多维数组。 与NumPy ndarray对象类似，tf.Tensor对象具有数据类型和形状。 此外，tf.Tensors可以驻留在加速器内存中（如GPU）。 TensorFlow提供了丰富的操作库（tf.add，tf.matmul，tf.linalg.inv等），它们使用和生成tf.Tensors。 这些操作会自动转换原生Python类型，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.5, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 5 13]\n",
      " [ 4  6]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(36, shape=(), dtype=int32)\n",
      "tf.Tensor(24, shape=(), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1.5,2))\n",
    "print(tf.add([[3,8], [2, 1]], [2,5]))\n",
    "print(tf.square(6))\n",
    "print(tf.reduce_sum([7,8,9]))\n",
    "print(tf.square(3)+tf.square(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个Tensor都有形状和类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6]\n",
      " [12]], shape=(2, 1), dtype=int32)\n",
      "(2, 1)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[3], [6]], [[2]])  # 2个张量的张量积\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy数组和tf.Tensors之间最明显的区别是：\n",
    "\n",
    "张量可以由加速器内存（如GPU，TPU）支持。\n",
    "张量是不可变的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy兼容性\n",
    "在TensorFlow tf.Tensors和NumPy ndarray之间转换很容易：\n",
    "\n",
    "TensorFlow操作自动将NumPy ndarrays转换为Tensors。\n",
    "NumPy操作自动将Tensors转换为NumPy ndarrays。\n",
    "使用.numpy（）方法将张量显式转换为NumPy ndarrays。 这些转换通常很容易的，因为如果可能，array和tf.Tensor共享底层内存表示。 但是，共享底层表示并不总是可行的，因为tf.Tensor可以托管在GPU内存中，而NumPy阵列总是由主机内存支持，并且转换涉及从GPU到主机内存的复制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[36. 36.]\n",
      " [36. 36.]], shape=(2, 2), dtype=float64)\n",
      "[[37. 37.]\n",
      " [37. 37.]]\n",
      "[[36. 36.]\n",
      " [36. 36.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ndarray = np.ones([2,2])\n",
    "tensor = tf.multiply(ndarray, 36)\n",
    "print(tensor)\n",
    "# 用np.add对tensorflow进行加运算\n",
    "print(np.add(tensor, 1))\n",
    "# 转换为numpy类型\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 GPU加速\n",
    "使用GPU进行计算可以加速许多TensorFlow操作。 如果没有任何注释，TensorFlow会自动决定是使用GPU还是CPU进行操作 - 如有必要，可以复制CPU和GPU内存之间的张量。 由操作产生的张量通常由执行操作的设备的存储器支持，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU availabel:\n",
      "False\n",
      "Is the Tensor on gpu #0:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "print('Is GPU availabel:')\n",
    "print(tf.test.is_gpu_available())\n",
    "print('Is the Tensor on gpu #0:')\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**设备名称**\n",
    "\n",
    "Tensor.device属性提供托管张量内容的设备的完全限定字符串名称。 此名称编码许多详细信息，例如正在执行此程序的主机的网络地址的标识符以及该主机中的设备。 这是分布式执行TensorFlow程序所必需的。 如果张量位于主机上的第N个GPU上，则字符串以GPU结尾：<N>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**显式设备放置(Placement)**\n",
    "\n",
    "在TensorFlow中，放置指的是如何分配（放置）设备以执行各个操作。 如上所述，如果没有提供明确的指导，TensorFlow会自动决定执行操作的设备，并在需要时将张量复制到该设备。 但是，可以使用tf.device上下文管理器将TensorFlow操作显式放置在特定设备上，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n",
      "10 loops: 1.6e+02ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def time_matmul(x):\n",
    "    start = time.time()\n",
    "    for loop in range(10):\n",
    "        tf.matmul(x, x)\n",
    "    result = time.time() - start\n",
    "    print('10 loops: {:0.2}ms'.format(1000*result))\n",
    "\n",
    "# 强制使用CPU\n",
    "print('On CPU:')\n",
    "with tf.device('CPU:0'):\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    # 使用断言验证当前是否为CPU0\n",
    "    assert x.device.endswith('CPU:0')\n",
    "    time_matmul(x)    \n",
    "\n",
    "# 如果存在GPU,强制使用GPU\n",
    "if tf.test.is_gpu_available():\n",
    "    print('On GPU:')\n",
    "    with tf.device.endswith('GPU:0'):\n",
    "        x = tf.random.uniform([1000, 1000])\n",
    "    # 使用断言验证当前是否为GPU0\n",
    "    assert x.device.endswith('GPU:0')\n",
    "    time_matmul(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 数据集\n",
    "本节使用tf.data.Dataset API构建管道，以便为模型提供数据。 tf.data.Dataset API用于从简单，可重复使用的部分构建高性能，复杂的输入管道，这些部分将为模型的培训或评估循环提供支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建源数据集**\n",
    "使用其中一个工厂函数（如Dataset.from_tensors，Dataset.from_tensor_slices）或使用从TextLineDataset或TFRecordDataset等文件读取的对象创建源数据集。 有关详细信息，请参阅TensorFlow数据集指南。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WWX649~1\\AppData\\Local\\Temp\\tmp52gb3fbb\n"
     ]
    }
   ],
   "source": [
    "# 从列表中获取tensor\n",
    "ds_tensors = tf.data.Dataset.from_tensor_slices([6,5,4,3,2,1])\n",
    "# 创建csv文件\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "print(filename)\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\"\"\")\n",
    "# 获取TextLineDataset数据集实例\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**应用转换**\n",
    "\n",
    "使用map，batch和shuffle等转换函数将转换应用于数据集记录。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**迭代**\n",
    "\n",
    "tf.data.Dataset对象支持迭代循环记录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_tensors中的元素：\n",
      "tf.Tensor([36 25], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16  9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "\n",
      "ds_file中的元素：\n",
      "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Line 3'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print('ds_tensors中的元素：')\n",
    "for x in ds_tensors:\n",
    "    print(x)\n",
    "# 从文件中读取的对象创建的数据源\n",
    "print('\\nds_file中的元素：')\n",
    "for x in ds_file:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
