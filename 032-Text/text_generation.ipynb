{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t09eeeR5prIJ"
   },
   "source": [
    "# TensorFlow2.0教程-使用RNN生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BwpJ5IffzRG6"
   },
   "source": [
    "本教程演示了如何使用基于字符的RNN生成文本。我们将使用Andrej Karpathy的“循环神经网络的不合理有效性”中的莎士比亚写作数据集。给定来自该数据的一系列字符（“Shakespear”），训练模型以预测序列中的下一个字符（“e”）。通过重复调用模型可以生成更长的文本序列。\n",
    "\n",
    "本教程包含使用tf.keras实现的可运行代码和急切执行。以下是本教程中的模型训练了30个纪元时的示例输出，并以字符串“Q”开头：\n",
    "\n",
    "<pre>\n",
    "QUEENE:\n",
    "I had thought thou hadst a Roman; for the oracle,\n",
    "Thus by All bids the man against the word,\n",
    "Which are so weak of care, by old care done;\n",
    "Your children were in your holy love,\n",
    "And the precipitation through the bleeding throne.\n",
    "\n",
    "BISHOP OF ELY:\n",
    "Marry, and will, my lord, to weep in such a one were prettiest;\n",
    "Yet now I was adopted heir\n",
    "Of the world's lamentable day,\n",
    "To watch the next way with his father with his face?\n",
    "\n",
    "ESCALUS:\n",
    "The cause why then we are all resolved more sons.\n",
    "\n",
    "VOLUMNIA:\n",
    "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
    "And love and pale as any will to that word.\n",
    "\n",
    "QUEEN ELIZABETH:\n",
    "But how long have I heard the soul for this world,\n",
    "And show his hands of life be proved to stand.\n",
    "\n",
    "PETRUCHIO:\n",
    "I say he look'd on, if I must be content\n",
    "To stay him from the fatal of our country's bliss.\n",
    "His lordship pluck'd from this sentence then for prey,\n",
    "And then let us twain, being the moon,\n",
    "were she such a case as fills m\n",
    "</pre>\n",
    "\n",
    "虽然有些句子是语法上的，但大多数句子都没有意义。该模型尚未学习单词的含义，但考虑：\n",
    "\n",
    "该模型基于字符。培训开始时，模型不知道如何拼写英语单词，或者单词甚至是文本单元。\n",
    "\n",
    "输出的结构类似于文本的播放块，通常以说话者名称开头，所有大写字母都类似于数据集。\n",
    "\n",
    "如下所示，模型是针对小批量文本（每个100个字符）进行训练的，并且仍然能够生成具有连贯结构的更长文本序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "## 开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### 导入TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6412,
     "status": "ok",
     "timestamp": 1564756501128,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "yG_n40gFzf9s",
    "outputId": "08cf79a9-4f5b-4ee2-afb7-209179e1949b"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# !pip install tensorflow-gpu==2.0.0-beta1\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHDoRoc5PKWz"
   },
   "source": [
    "### 下载莎士比亚数据集\n",
    "更改以下行以在您自己的数据上运行此代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UHjdCjDuSvX_"
   },
   "source": [
    "### 观察数据\n",
    "\n",
    "首先， 观察文字:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8756,
     "status": "ok",
     "timestamp": 1564756503495,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "aavnuByVymwK",
    "outputId": "9eabfb6e-a151-4ef3-e8da-4c3df1c045bf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of text: 1115394 characters\n"
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8749,
     "status": "ok",
     "timestamp": 1564756503495,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "Duhg9NrUymwO",
    "outputId": "127f9e8c-71cc-4c8e-e09d-555e7f20164a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\n"
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8741,
     "status": "ok",
     "timestamp": 1564756503496,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "IlCgQBRVymwR",
    "outputId": "d430e2fd-8c5d-4798-eeec-8d24ce3dec5c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "65 unique characters\n"
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## 处理文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### 矢量化文本\n",
    "在训练之前，我们需要将字符串映射到数字表示。创建两个查找表：一个将字符映射到数字，另一个用于数字到字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {char:index for index, char in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# 文本str -> int\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1115394,)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "text_as_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "现在我们有一个每个字符的整数表示。请注意，我们将字符映射为从0到的索引len(unique)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9081,
     "status": "ok",
     "timestamp": 1564756503855,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "FYyNlCNXymwY",
    "outputId": "7293ffef-0ed8-4ae6-9a54-3397f989b83c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\n  '\\n':   0,\n  ' ' :   1,\n  '!' :   2,\n  '$' :   3,\n  '&' :   4,\n  \"'\" :   5,\n  ',' :   6,\n  '-' :   7,\n  '.' :   8,\n  '3' :   9,\n  ':' :  10,\n  ';' :  11,\n  '?' :  12,\n  'A' :  13,\n  'B' :  14,\n  'C' :  15,\n  'D' :  16,\n  'E' :  17,\n  'F' :  18,\n  'G' :  19,\n  ...\n}\n"
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9073,
     "status": "ok",
     "timestamp": 1564756503855,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "l1VKcQHcymwb",
    "outputId": "0fac4352-89b7-4a9d-c2b4-8e9b38db5714"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "### 预测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wssHQ1oGymwe"
   },
   "source": [
    "\n",
    "给定一个字符或一系列字符，最可能的下一个字符是什么？这是我们正在训练模型执行的任务。模型的输入将是一系列字符，我们训练模型以预测输出 - 每个时间步的后续字符。\n",
    "\n",
    "由于RNN维持一个取决于之前看到的元素的内部状态，给定此时计算的所有字符，下一个字符是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### 创建培训示例和目标\n",
    "接下来将文本划分为示例序列。每个输入序列将包含seq_length文本中的字符。\n",
    "\n",
    "对于每个输入序列，相应的目标包含相同长度的文本，除了向右移动一个字符。\n",
    "\n",
    "所以把文本分成几块seq_length+1。例如，假设seq_length是4，我们的文本是“你好”。输入序列是“Hell”，目标序列是“ello”。\n",
    "\n",
    "为此，首先使用该tf.data.Dataset.from_tensor_slices函数将文本向量转换为字符索引流。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9448,
     "status": "ok",
     "timestamp": 1564756504237,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "0UHJDA39zf-O",
    "outputId": "9e7df249-7f19-4689-804c-8705f79792a5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F\ni\nr\ns\nt\n"
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):  # 前5个字符\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "该batch方法可以让我们轻松地将这些单个字符转换为所需大小的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9437,
     "status": "ok",
     "timestamp": 1564756504238,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "l4hkDU3i7ozi",
    "outputId": "a95fabae-b3fa-460f-b664-7d66d13cabeb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
    }
   ],
   "source": [
    "# 每101个字符 会生成一对(X, Y)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "对于每个序列，复制并移动它以形成输入和目标文本，map方法是使用该方法将简单函数应用于每个批处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiCopyGZymwi"
   },
   "source": [
    "打印第一个示例输入和目标值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9411,
     "status": "ok",
     "timestamp": 1564756504239,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "GNbw-iR0ymwj",
    "outputId": "4240109b-6f9f-46b2-8126-609fee3b7bf4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\nTarget data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_33OHL3b84i0"
   },
   "source": [
    "这些矢量的每个索引作为一个时间步骤处理。对于时间步骤0的输入，模型接收“F”和trys的索引以预测“i”的索引作为下一个字符。在下一个时间步，它做同样的事情，但RNN除了当前输入字符之外还考虑前一步骤上下文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10188,
     "status": "ok",
     "timestamp": 1564756505026,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "0eBu9WZG84i0",
    "outputId": "0a467f77-f745-45b6-dc7f-559a4f4a05a5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Step    0\n  input: 18 ('F')\n  expected output: 47 ('i')\nStep    1\n  input: 47 ('i')\n  expected output: 56 ('r')\nStep    2\n  input: 56 ('r')\n  expected output: 57 ('s')\nStep    3\n  input: 57 ('s')\n  expected output: 58 ('t')\nStep    4\n  input: 58 ('t')\n  expected output: 1 (' ')\n"
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### 创建培训批次\n",
    "我们过去常常tf.data将文本拆分为可管理的序列。但在将这些数据输入模型之前，我们需要对数据进行混洗并将其打包成批。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10178,
     "status": "ok",
     "timestamp": 1564756505027,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "p2pGotuNzf-S",
    "outputId": "3d934eef-7b8d-4391-af37-67de1d850b7e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "\n",
    "使用tf.keras.Sequential来定义模型。对于这个简单的例子，三层用于定义我们的模型：\n",
    "\n",
    "- tf.keras.layers.Embedding：输入图层。一个可训练的查找表，它将每个字符的数字映射到具有embedding_dim维度的向量;\n",
    "- tf.keras.layers.GRU：一种具有大小的RNN units=rnn_units（您也可以在此处使用LSTM层。）\n",
    "- tf.keras.layers.Dense：输出层，带vocab_size输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "65"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mInit signature:\u001b[0m\n\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0membeddings_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmask_zero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \nTurns positive integers (indexes) into dense vectors of fixed size.\n\ne.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n\nThis layer can only be used as the first layer in a model.\n\nExample:\n\n```python\nmodel = Sequential()\nmodel.add(Embedding(1000, 64, input_length=10))\n# the model will take as input an integer matrix of size (batch,\n# input_length).\n# the largest integer (i.e. word index) in the input should be no larger\n# than 999 (vocabulary size).\n# now model.output_shape == (None, 10, 64), where None is the batch\n# dimension.\n\ninput_array = np.random.randint(1000, size=(32, 10))\n\nmodel.compile('rmsprop', 'mse')\noutput_array = model.predict(input_array)\nassert output_array.shape == (32, 10, 64)\n```\n\nArguments:\n  input_dim: int > 0. Size of the vocabulary,\n    i.e. maximum integer index + 1.\n  output_dim: int >= 0. Dimension of the dense embedding.\n  embeddings_initializer: Initializer for the `embeddings` matrix.\n  embeddings_regularizer: Regularizer function applied to\n    the `embeddings` matrix.\n  embeddings_constraint: Constraint function applied to\n    the `embeddings` matrix.\n  mask_zero: Whether or not the input value 0 is a special \"padding\"\n    value that should be masked out.\n    This is useful when using recurrent layers\n    which may take variable length input.\n    If this is `True` then all subsequent layers\n    in the model need to support masking or an exception will be raised.\n    If mask_zero is set to True, as a consequence, index 0 cannot be\n    used in the vocabulary (input_dim should equal size of\n    vocabulary + 1).\n  input_length: Length of input sequences, when it is constant.\n    This argument is required if you are going to connect\n    `Flatten` then `Dense` layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n\nInput shape:\n  2D tensor with shape: `(batch_size, input_length)`.\n\nOutput shape:\n  3D tensor with shape: `(batch_size, input_length, output_dim)`.\n\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/embeddings.py\n\u001b[0;31mType:\u001b[0m           type\n\u001b[0;31mSubclasses:\u001b[0m     \n"
    }
   ],
   "source": [
    "tf.keras.layers.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              # 不指定input_length, 为了测试时生成不同长度文本考虑\n",
    "                              batch_input_shape=[batch_size, None]),  \n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    # tf.keras.layers.GRU(rnn_units,\n",
    "    #                     return_sequences=True,\n",
    "    #                     stateful=True,\n",
    "    #                     recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkA5upJIJ7W7"
   },
   "source": [
    "对于每个字符，模型查找嵌入，以嵌入作为输入一次运行GRU，并应用密集层生成预测下一个字符的对数似然的logits：\n",
    "\n",
    "<img src=\"https://tensorflow.org/tutorials/beta/text/images/text_generation_training.png\">通过模型的数据图</img>\n",
    "\n",
    "\n",
    "![通过模型的数据图](https://tensorflow.org/tutorials/beta/text/images/text_generation_training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14636,
     "status": "ok",
     "timestamp": 1564756509532,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "vPGmAAXmVLGC",
    "outputId": "d0b9e5b6-33ca-456f-eec5-0295777b91d0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (64, None, 256)           16640     \n_________________________________________________________________\nlstm (LSTM)                  (64, None, 1024)          5246976   \n_________________________________________________________________\ndense (Dense)                (64, None, 65)            66625     \n=================================================================\nTotal params: 5,330,241\nTrainable params: 5,330,241\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## 测试模型\n",
    "现在运行模型以查看它的行为符合预期。\n",
    "\n",
    "首先检查输出的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14644,
     "status": "ok",
     "timestamp": 1564756509531,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "C-_70kKAPrPU",
    "outputId": "c23fee0b-d816-4d3c-b363-e26693450ccf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(64, 100)\n(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(input_example_batch.shape)\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6NzLBi4VM4o"
   },
   "source": [
    "在上面的例子中，输入的序列长度是，100但模型可以在任何长度的输入上运行："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "为了从模型中获得实际预测，我们需要从输出分布中进行采样，以获得实际的字符索引。此分布由字符词汇表上的logits定义。\n",
    "> 注意：从这个分布中进行采样非常重要，因为采用分布的argmax可以很容易地将模型卡在循环中。\n",
    "\n",
    "尝试批处理中的第一个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(100, 65), dtype=float32, numpy=\narray([[ 0.00404359,  0.00288558,  0.00215357, ..., -0.00045593,\n        -0.00293113, -0.00260316],\n       [ 0.00073711,  0.00550455,  0.00546801, ...,  0.00323724,\n         0.00089605, -0.00147596],\n       [ 0.00346867,  0.00400022,  0.00560515, ...,  0.00242463,\n         0.00024617, -0.00369232],\n       ...,\n       [ 0.00267898,  0.00043139, -0.00302298, ..., -0.00372706,\n         0.00450641,  0.00241301],\n       [ 0.00282291, -0.00078044, -0.00247648, ..., -0.00019255,\n         0.00312746, -0.00044447],\n       [-0.0004436 ,  0.00416891,  0.00081265, ...,  0.00518154,\n         0.00840197, -0.0064987 ]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mSignature:\u001b[0m\n\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nDraws samples from a categorical distribution.\n\nExample:\n\n```python\n# samples has shape [1, 5], where each value is either 0 or 1 with equal\n# probability.\nsamples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 5)\n```\n\nArgs:\n  logits: 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice\n    `[i, :]` represents the unnormalized log-probabilities for all classes.\n  num_samples: 0-D.  Number of independent samples to draw for each row slice.\n  dtype: integer type to use for the output. Defaults to int64.\n  seed: A Python integer. Used to create a random seed for the distribution.\n    See `tf.compat.v1.set_random_seed` for behavior.\n  name: Optional name for the operation.\n\nReturns:\n  The drawn samples of shape `[batch_size, num_samples]`.\n\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/random_ops.py\n\u001b[0;31mType:\u001b[0m      function\n"
    }
   ],
   "source": [
    "# 需要使用未归一化(softmax)的数据\n",
    "tf.random.categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(100, 1)\n"
    }
   ],
   "source": [
    "# 对第一个样本进行随机采样  [batch_size, num_classes]=(100, 65)  - > (100 , 1)\n",
    "# 使用argmax 会生成相同的文本\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "print(sampled_indices.shape)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QM1Vbxs_URw5"
   },
   "source": [
    "这使我们在每个时间步都预测下一个字符索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14593,
     "status": "ok",
     "timestamp": 1564756509532,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "YqFMUQc_UFgM",
    "outputId": "6046fe90-c765-4edd-bb56-2e29557b5fe8"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([37, 40,  4, 15, 22,  4, 18,  2, 31,  7, 11, 16, 50, 47,  7, 28, 20,\n       54, 21, 61, 50, 35, 47,  3, 59,  9, 53, 10, 34, 31, 51, 52,  4, 40,\n        1, 48, 37, 63, 22, 61, 49, 40, 17, 32, 14,  6, 29, 34, 33, 55, 41,\n       57, 15, 16, 53, 50, 46, 61, 18, 58, 15,  8,  8, 62,  6, 51, 24,  7,\n       39, 19, 24, 29, 51,  4, 50, 57,  0, 46, 58, 14, 35, 52,  7,  8, 51,\n       17, 25, 30, 61, 44, 44,  2, 14, 36, 52, 22,  8, 19, 22, 33])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "解码这些以查看此未经训练的模型预测的文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14578,
     "status": "ok",
     "timestamp": 1564756509533,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "xWcFwPwLSo05",
    "outputId": "5bd7b655-3417-4209-b5fb-394f0e62ab1f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input: \n 'nd it to be true,\\nI never thought it possible or likely;\\nBut see, while idly I stood looking on,\\nI f'\n\nNext Char Predictions: \n 'Yb&CJ&F!S-;Dli-PHpIwlWi$u3o:VSmn&b jYyJwkbETB,QVUqcsCDolhwFtC..x,mL-aGLQm&ls\\nhtBWn-.mEMRwff!BXnJ.GJU'\n"
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCbHQHiaa4Ic"
   },
   "source": [
    "此时，问题可以被视为标准分类问题。给定先前的RNN状态，以及此时间步的输入，预测下一个字符的类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "### 附加优化器和损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "标准tf.keras.losses.sparse_categorical_crossentropy损失函数在这种情况下有效，因为它应用于预测的最后一个维度。\n",
    "\n",
    "因为我们的模型返回logits，所以我们需要设置from_logits标志。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14568,
     "status": "ok",
     "timestamp": 1564756509533,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "4HrXTACTdzY-",
    "outputId": "90eb3df2-4df4-4732-e28a-4a3bd3473f11"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\nscalar_loss:       4.174947\n"
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(64, 100)"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "example_batch_loss.numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeOXriLcymww"
   },
   "source": [
    "使用该tf.keras.Model.compile方法配置培训过程。我们将使用tf.keras.optimizers.Adam默认参数和损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### 配置检查点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6XBUUavgF56"
   },
   "source": [
    "使用a tf.keras.callbacks.ModelCheckpoint确保在培训期间保存检查点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)  # 保留每个epoch的weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### 执行培训"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxdOA-rgyGvs"
   },
   "source": [
    "为了使训练时间合理，使用10个时期来训练模型。在Colab中，将运行时设置为GPU以便更快地进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 153379,
     "status": "ok",
     "timestamp": 1564756648387,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "UK-hmKjYVoll",
    "outputId": "794f87e8-ff8d-43ef-d4da-472f94f0cbba"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 172 steps\nEpoch 1/50\n172/172 [==============================] - 41s 240ms/step - loss: 2.6168\nEpoch 2/50\n172/172 [==============================] - 41s 236ms/step - loss: 1.8878\nEpoch 3/50\n172/172 [==============================] - 40s 230ms/step - loss: 1.6360\nEpoch 4/50\n172/172 [==============================] - 39s 229ms/step - loss: 1.5030\nEpoch 5/50\n172/172 [==============================] - 40s 231ms/step - loss: 1.4242\nEpoch 6/50\n172/172 [==============================] - 40s 230ms/step - loss: 1.3693\nEpoch 7/50\n172/172 [==============================] - 39s 230ms/step - loss: 1.3249\nEpoch 8/50\n172/172 [==============================] - 40s 231ms/step - loss: 1.2856\nEpoch 9/50\n172/172 [==============================] - 39s 229ms/step - loss: 1.2515\nEpoch 10/50\n172/172 [==============================] - 39s 229ms/step - loss: 1.2163\nEpoch 11/50\n172/172 [==============================] - 40s 232ms/step - loss: 1.1813\nEpoch 12/50\n172/172 [==============================] - 40s 230ms/step - loss: 1.1454\nEpoch 13/50\n172/172 [==============================] - 39s 229ms/step - loss: 1.1091\nEpoch 14/50\n172/172 [==============================] - 40s 233ms/step - loss: 1.0705\nEpoch 15/50\n172/172 [==============================] - 40s 230ms/step - loss: 1.0314\nEpoch 16/50\n172/172 [==============================] - 39s 229ms/step - loss: 0.9911\nEpoch 17/50\n172/172 [==============================] - 40s 232ms/step - loss: 0.9506\nEpoch 18/50\n172/172 [==============================] - 40s 230ms/step - loss: 0.9106\nEpoch 19/50\n172/172 [==============================] - 39s 229ms/step - loss: 0.8693\nEpoch 20/50\n172/172 [==============================] - 40s 232ms/step - loss: 0.8309\nEpoch 21/50\n172/172 [==============================] - 40s 231ms/step - loss: 0.7944\nEpoch 22/50\n172/172 [==============================] - 39s 229ms/step - loss: 0.7595\nEpoch 23/50\n172/172 [==============================] - 40s 231ms/step - loss: 0.7281\nEpoch 24/50\n172/172 [==============================] - 40s 232ms/step - loss: 0.6985\nEpoch 25/50\n172/172 [==============================] - 39s 228ms/step - loss: 0.6708\nEpoch 26/50\n172/172 [==============================] - 40s 231ms/step - loss: 0.6455\nEpoch 27/50\n172/172 [==============================] - 40s 233ms/step - loss: 0.6241\nEpoch 28/50\n172/172 [==============================] - 40s 230ms/step - loss: 0.6033\nEpoch 29/50\n172/172 [==============================] - 40s 230ms/step - loss: 0.5844\nEpoch 30/50\n172/172 [==============================] - 40s 232ms/step - loss: 0.5675\nEpoch 31/50\n172/172 [==============================] - 39s 228ms/step - loss: 0.5527\nEpoch 32/50\n172/172 [==============================] - 40s 232ms/step - loss: 0.5387\nEpoch 33/50\n172/172 [==============================] - 39s 229ms/step - loss: 0.5268\nEpoch 34/50\n172/172 [==============================] - 39s 229ms/step - loss: 0.5162\nEpoch 35/50\n172/172 [==============================] - 40s 232ms/step - loss: 0.5053\nEpoch 36/50\n172/172 [==============================] - 39s 229ms/step - loss: 0.4960\nEpoch 37/50\n172/172 [==============================] - 39s 230ms/step - loss: 0.4889\nEpoch 38/50\n172/172 [==============================] - 40s 232ms/step - loss: 0.4803\nEpoch 39/50\n172/172 [==============================] - 39s 228ms/step - loss: 0.4747\nEpoch 40/50\n172/172 [==============================] - 40s 230ms/step - loss: 0.4668\nEpoch 41/50\n172/172 [==============================] - 41s 236ms/step - loss: 0.4602\nEpoch 42/50\n172/172 [==============================] - 44s 253ms/step - loss: 0.4543\nEpoch 43/50\n172/172 [==============================] - 44s 255ms/step - loss: 0.4508\nEpoch 44/50\n172/172 [==============================] - 44s 256ms/step - loss: 0.4470\nEpoch 45/50\n172/172 [==============================] - 44s 254ms/step - loss: 0.4428\nEpoch 46/50\n172/172 [==============================] - 44s 257ms/step - loss: 0.4385\nEpoch 47/50\n172/172 [==============================] - 44s 256ms/step - loss: 0.4344\nEpoch 48/50\n172/172 [==============================] - 44s 253ms/step - loss: 0.4310\nEpoch 49/50\n172/172 [==============================] - 44s 257ms/step - loss: 0.4287\nEpoch 50/50\n172/172 [==============================] - 44s 256ms/step - loss: 0.4257\n"
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## 生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIPcXllKjkdr"
   },
   "source": [
    "### 恢复最新的检查点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyeYRiuVjodY"
   },
   "source": [
    "\n",
    "要使此预测步骤简单，请使用批处理大小1。\n",
    "\n",
    "由于RNN状态从时间步长传递到时间步的方式，模型一旦构建就只接受固定的批量大小。\n",
    "\n",
    "要使用不同的模型运行模型batch_size，我们需要重建模型并从检查点恢复权重。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 153371,
     "status": "ok",
     "timestamp": 1564756648388,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "zk2WJ2-XjkGz",
    "outputId": "9088cc5b-bafa-49cb-a3a4-ee5341b578ce"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'./training_checkpoints/ckpt_50'"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "# 用于生成文本 的 模型\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 154683,
     "status": "ok",
     "timestamp": 1564756649725,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "71xa6jnYVrAN",
    "outputId": "66ae1561-327f-47b9-c1eb-a6226417d126"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (1, None, 256)            16640     \n_________________________________________________________________\nlstm_1 (LSTM)                (1, None, 1024)           5246976   \n_________________________________________________________________\ndense_1 (Dense)              (1, None, 65)             66625     \n=================================================================\nTotal params: 5,330,241\nTrainable params: 5,330,241\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "预测循环\n",
    "以下代码块生成文本：\n",
    "\n",
    "- 它首先选择一个起始字符串，初始化RNN状态并设置要生成的字符数。\n",
    "\n",
    "- 使用起始字符串和RNN状态获取下一个字符的预测分布。\n",
    "\n",
    "- 然后，使用分类分布来计算预测字符的索引。使用此预测字符作为模型的下一个输入。\n",
    "\n",
    "- 模型返回的RNN状态被反馈到模型中，以便它现在具有更多上下文，而不是仅有一个单词。在预测下一个单词之后，修改后的RNN状态再次反馈到模型中，这是它从先前预测的单词获得更多上下文时的学习方式。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![要生成文本，模型的输出将反馈到输入](https://tensorflow.org/tutorials/beta/text/images/text_generation_sampling.png)\n",
    "查看生成的文本，您将看到模型知道何时大写，制作段落并模仿类似莎士比亚的写作词汇。由于训练时代数量较少，尚未学会形成连贯的句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  print(\"输入字符:\", input_eval.shape)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  # 初始化RNN的状态向量\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      # input (1, None)  out (1, None, 65) \n",
    "      predictions = model(input_eval)  \n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)  # [None, 65]\n",
    "\n",
    "      # using a categorical distribution to predict the word returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      # (None, 1)[-1, 0]\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      # X^<t> = y^<t-1>\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159152,
     "status": "ok",
     "timestamp": 1564756654219,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "ktovv0RFhrkn",
    "outputId": "e7139557-b924-4656-da8e-a7e3f15ddc98"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "输入字符: (1, 1)\nRICHAMIO:\nNo, noble prince, thou shouldst have met again\nAnd glink thee, tire-tremble. How long have you this\nMy words disbench'd you not.\n\nCORIOLANUS:\nI'll say ith the deed?\n\nSecond Watchman:\nTo-morrow this:\nUpon my life, Pompey? it is hoow, when I should break on a\ngaf vex him once again;\nFor though you live to see your kindred's tears:\nAs when withir\nVure one and white posterns or two\nISABELLA:\nShow me how, good father.\n\nDUKE VINCENTIO:\nBy this my body's goods, and longing, stabbed with a\nbrain'd stephend hath got the way,\nHeaven and of which pines I plead\nAnd he shall speak for them, it should proceed:\nI'll draw the cause with you, by your leave,\nThat we have no discover'd, it shall be studned at his hat!\nO, tell me, didst thou not aspirit,\nWhile I stand fooling in one less? or I swear perform'd you from a maid.\n\nVIRGILIA:\nThe sway is to make his and look in heaven.\nO woman' when\nThy by my soul's red jost to serve\nOf his own good curse my misfit like\nA place of statelf; ere lies the\n"
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"R\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "你可以做的最简单的事情是改善结果，以便更长时间地训练它（尝试EPOCHS=30）。\n",
    "\n",
    "您还可以尝试使用不同的起始字符串，或尝试添加另一个RNN图层以提高模型的准确性，或者调整温度参数以生成更多或更少的随机预测。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4QwTjAM6A2O"
   },
   "source": [
    "## 上述训练程序很简单，但不会给你太多控制。\n",
    "\n",
    "所以现在您已经了解了如何手动运行模型，让我们解压缩训练循环，并自己实现。例如，如果要实施课程学习以帮助稳定模型的开环输出，这就是一个起点。\n",
    "\n",
    "我们将用于tf.GradientTape跟踪渐变。您可以通过阅读热切的执行指南来了解有关此方法的更多信息。\n",
    "\n",
    "该程序的工作原理如下：\n",
    "\n",
    "- 首先，初始化RNN状态。我们通过调用tf.keras.Model.reset_states方法来完成此操作。\n",
    "\n",
    "- 接下来，迭代数据集（逐批）并计算与每个数据集关联的预测。\n",
    "\n",
    "- 打开a tf.GradientTape，并计算该上下文中的预测和损失。\n",
    "\n",
    "- 使用该tf.GradientTape.grads方法计算相对于模型变量的损失梯度。\n",
    "\n",
    "- 最后，使用优化器的tf.train.Optimizer.apply_gradients方法向下迈出一步。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XAm7eCoKULT"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUKhnZtMVpoJ"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4kH1o0leVIp"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, target):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(inp)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            target, predictions, from_logits=True))\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 295217,
     "status": "ok",
     "timestamp": 1564756790330,
     "user": {
      "displayName": "Will Chen",
      "photoUrl": "",
      "userId": "01179718990779759737"
     },
     "user_tz": -480
    },
    "id": "d4tSNwymzf-q",
    "outputId": "894696d7-6ac7-4e0e-f469-ce07f98ac3d3"
   },
   "outputs": [],
   "source": [
    "# Training step\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  # initializing the hidden state at the start of every epoch\n",
    "  # initally hidden is None\n",
    "  hidden = model.reset_states()\n",
    "\n",
    "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "    loss = train_step(inp, target)\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "      template = 'Epoch {} Batch {} Loss {}'\n",
    "      print(template.format(epoch+1, batch_n, loss))\n",
    "\n",
    "  # saving (checkpoint) the model every 5 epochs\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "  print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_9USpdHlYtt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:tpu_hw_notebook",
    "kind": "private"
   },
   "name": "text_generation.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/text/text_generation.ipynb",
     "timestamp": 1564754299619
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python37664bittf2conda2a75a45106264ceab7472c43279a5d24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}